\JWlone{Implementation}

%#  DATA FORMATS  ##############################################################
\JWltwo{Data Formats}
\label{sec:data-formats}

This chapter will give a rough outline of the formats used to store data between
the various phases of the analysis. The lingua franca for most complex on disc
formats are the schrieblesque \JWTprotobuf. Though, when interfacing with
external software such as \JWTR, other formats had to be chosen. The choice in
favour of Protocol Buffers has been made because of \emph{think XML, but
smaller, faster, and simpler} (which is incidentally their  slogan).

%-  shot ids  ------------------------------------------------------------------
\JWlthree{Shot IDs}
\label{sec:shot-ids}

A shot ID (shot identifier) is a string value uniquely identifiying one
measuring experiment. More precisely it's a character string containing only a
defined set of ASCII characters. The following regular expression shoud match
all allowed shot IDs: \verb%[a-zA-Z0-9@_-]{1,64}%.

Such shot IDs are always used to associated power and performance event
measurings.


%-  voltage drop data point files  ---------------------------------------------
\JWlthree{Electrical Power Data Point Files}
\label{sec:datapoint-files}

The main matter of the \emph{electrical power data point files} (called
\emph{data point files} for simplicity) is to log the CPU's power consumation by
time. As described in chapter \ref{sec:measuring-setup}, voltage drops are
measured and electrical power and work are only calculated later on. This is
why data point files do literally contain voltage drop values by time.
But since the only reason they exist is to serve as calculation input later on,
they are named after their future meaning.

For practical reasons the representation was designed rather flexible: It
supports arbitrary sampling rates, an arbitrary number of (named) channels and
high-resolution timestamps (up to \SI{1}{\nano\second}).

While doing the research for this thesis, three channels have been recorded with
a sampling rate of \SI{50}{\kilo\samples\per\second}: \texttt{CPU} -- the CPU's
voltage drops, \texttt{BOARD} -- the mainboard's voltage drops (unused) and
\texttt{TRIGGER} -- the trigger cable used to mark the periods of time the
other machine counted performance events.

The data point files are also one notable exception of the \emph{Protocol
Buffers for everything} principle in this work. As \cite{google11pbtechniques}
states the Procotol Buffers were not designed to handle large messages
but are great as individual messages \emph{within} a large data set. So (as you
can see in appendix \ref{sec:fmt:datapoints}) small Protocol Buffer messages
are streamed one after another. The size of one of these chunks is not
specified. Usually one makes up a chunk when he receives one from a measuring
device. The rule of thumb is: Make them as large as practical, but not too large
since we only record one timestamp per chunk. The data points inside each chunk
are considered as distributed equally.


\ref{sec:fmt:datapoints}






%-  performance counter files  -------------------------------------------------
\JWlthree{Counter Files}
\label{sec:counter-files}


%-  work files  ----------------------------------------------------------------
\JWlthree{Work Files}
\label{sec:work-files}

The content of the work files is really just the electrical work of a certain
measuring experiment in Joule. The file format is the ASCII representation of a
floating point value followed by optional garbage (separated by an ASCII space
or newline). In contrast to the other file formats, the work file's file names
have to match the following format: \verb%work_<SHOT-ID>_.work% (e.g.
\verb%work_SPEC-gcc@2011-08-31_16-07-46.work%).

A valid work file could look like

\begin{lstlisting}[style=Shell]
$ hexdump -C work_SPEC-gcc@2011-08-31_16-07-46.work
0000  37 34 2e 30 31 35 32 35  36 0a   |74.015256.|
000a
\end{lstlisting}.




%#  TOOLS  #####################################################################
\JWltwo{Tools}
\label{sec:tools}

Since the building of a reasonable energy model is not an easy task, numerous
tools have been used. Most of the tools were developed specifically for the
purpose of this study thesis. All of them are open-sourced and available on
\JWnamedlink{https://github.com/weissi/studienarbeit}{GitHub}.

In this chapter, we will give an overview of the software used, both standard
software and tools developed specifically to be able to write this paper.


%-  standard software  ---------------------------------------------------------
\JWlthree{Standard Software}
\label{sec:standard-software}

\begin{itemize}

\item \JWTprotobuf for saving and loading of all kinds of data

\item \JWnamedlink{http://www.r-project.org/}{R} for statistical computations

\item \JWnamedlink{http://cran.r-project.org/web/packages/leaps/}{leaps package}
      , a R library for regression subset selection (to minimize the set of
      available performance counters)

\item \JWnamedlink{http://stat.ethz.ch/R-manual/R-devel/library/stats/html/lm.html}
      {lm library}, a R library used to fit linear models

\item \JWnamedlink{http://kernel.org}{Linux Kernel}

\item \JWnamedlink{http://gnu.org}{numerous GNU tools}

\item \JWnamedlink{http://perfmon2.sourceforge.net/docs_v4.html}
      {\texttt{libpfm4}} for reading the performance counters from userspace

\end{itemize}


%-  special developments  ------------------------------------------------------
\JWlthree{Special Developments}
\label{sec:special-developments}


\JWlfour{\JWTlibdp}

\JWTlibdp is responsible for loading and saving the measured data points from
and to the \JWTprotobuf files. It's API is straight forward and it is able to
handle very big files. The API can be found in
\JWpath{libdatapoints/datapoints.h}.


\JWlfour{\JWTfcw}

\JWTfcw can calculate the electrical work from data points files very quickly.
As explained in section \ref{sec:calc-work} it integrates to electrical power.
But since we obtain discrete data by sampling (see section
\ref{sec:measuring-setup}) the integration can be done quite fast:

\JWtodo{integral P = sum P * diff}

A typical call to \JWTfcw looks like

\begin{lstlisting}[style=Shell]
fastcalcwork captured-17:15:00.dpts CPU 0.01 TRIGGER
\end{lstlisting}

Using the command line above, \JWTfcw will calculate the electrical work with a
measuring resistor of \SI{0.01}{\ohm}. The measured data points will be taken
from column \texttt{CPU}, the analog trigger's (see section
\ref{sec:measuring-setup}) value from \texttt{TRIGGER}.


\JWlfour{\JWTdc}

\JWTdc is the tool for retrieving the performance counter's values on the target
machine. Giving it a set of performance counters and a command to execute, it
will record the counters while the command is running. It always works
system-wide and saves values by counter and by CPU enabled.

A working example:

\begin{lstlisting}[style=Shell]
dumpcounters -e CPU_CLK_UNHALTED,INST_RETIRED -r ls
\end{lstlisting}

The exact data format is documented in \JWpath{protos/perf-counters.proto}.

\JWlfour{\JWTde}

\JWTde exports data point files (see section \ref{sec:datapoint-files}) to a
format \JWTR can easily use.

\JWtodo{bib ref to R table format}.

\JWlfour{\JWTdd}

\JWlfour{\JWTcbs suite}

\JWlfour{\JWTbsle}

\JWTbsle is a \JWnamedlink{http://haskell.org}{Haskell} program which is able
\emph{build} the \emph{s}ystem of \emph{l}inear \emph{e}quations. It takes
several counter files (\ref{sec:counter-files}) and the corresponding work files
(\ref{sec:work-files}) as input and outputs a system of linear equations.

\JWlfour{high-level scripts}


%#  TOWARD THE ENERGY MODEL  ###################################################
\JWltwo{Toward the Energy Model}
\label{sec:towards-the-model}

In this chapter a description of the steps toward the final energy model(s) is
given.


%-  BENCHMARKS  ----------------------------------------------------------------
\JWlthree{The set of Benchmarks}
\label{sec:benchmarks}

How and which benchmarks did I choose?


%-  SUBSET OF USEFUL COUNTERS  -------------------------------------------------
\JWlthree{Finding a useful Subset of Events}

This section will feature a practical description of
\ref{sec:methods-of-analysis}.

\begin{itemize}

\item 1 CPU, all events, rotational

\item 1 CPU enabled, chosen events

\item 2 CPUs enabled, chosen events

\item 3 CPUs enabled, chosed events

\item 4 CPUs enabled, chosed events

\end{itemize}



% vim: set spell spelllang=en_us fileencoding=utf8 :
